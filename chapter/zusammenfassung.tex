%!TEX root=../documentation-bachlorthesis-speicherarchitektur-lstucker.tex
\cleardoublepage
\chapter{Zusammenfassung}

Der Auftraggeber, ein Zürcher Startup Unternehmen, betreibt und entwickelt eine Bild-Archiv Webapplikation für Kunden mit hohen Ansprüchen an die Qualität ihrer Bilder. Die Anwendung erlaubt das Speichern, Archivieren, Verwalten und die Druckaufbereitung von qualitativ hochauflösenden digitalen Bildern. Ein einzelnes Bild kann eine Speichergrösse von bis zu 2 Gigabyte beanspruchen. Das Archiv belegt schon heute mehr als 2.5 Terrabyte Diskplatz.
Die Aufgabe dieser Arbeit besteht darin, ein geeignetes Speichersystem zu evaluieren, welches die Anforderungen für eine Speichergrösse von 11.5 Tebibyte in Szenario 1 und für 218 Tebibyte in Szenario 2 am besten erfüllt. In der Arbeit sollen die Anforderungen bezüglich Skalierbarkeit der Speicherkapazität und Anzahl Datenabfragen, der Datendurchsatz, die Datenverfügbarkeit, die Datenintegrität und Wirtschaftlichkeit des Gesamtsystems untersucht werden.
Bis anhin werden die Daten auf einem einzelnen gehosteten Server gespeichert, auf welchem auch die Webapplikation betrieben wird. Um die Daten vor Verlust zu schützen, sind die Festplatten des Servers mit einem RAID-5 System konfiguriert. Die verfügbare Speicherkapazität ist bereits zu über 50\% ausgelastet und kann nicht ohne Upgrade auf ein neues System erweitert werden. Bei gleichbleibendem Datenwachstum ist die freie Kapazität innert sieben Monaten ausgeschöpft. Das bestehende System kann die Anforderungen bezüglich Verfügbarkeit und Skalierbarkeit nicht erfüllen. Das Überdenken der künftigen Speicherarchitektur drängt sich deshalb auf.
 Die heutigen am Markt erhältlichen Speicherarchitekturen lassen sich in der obersten Kategorie in Block-, Datei- und Objekt-basierte Systeme unterteilen. Die Block-basierende Speicherarchitektur ist wohl die traditionellste und die am weitverbreitetste Form von allen. Block-basierende Speicher können mittels FibreChannel oder iSCSI über ein Speichernetzwerk (SAN) an mehrere Server-Systeme zur Verfügung gestellt werden. Mit dem Aufkommen von Desktop-Computern, wuchs der Bedarf die Daten zentral für alle Benutzer ablegen und dezentral auf diese zugreifen zu können. Aus dieser Anforderung heraus wurden die Datei-basierenden Speicherarchitekturen entwickelt. Dazu gehört Network File System (NFS). Objekt-basierende Speichersysteme werden zunehmend bei sehr hohem Speicherkapazitätsbedarf oder wo die Daten für Datenanalyse aus Performanceoptimierung auf verschiedene Systeme gespeichert werden sollen.
Für die Evaluation wurde das Analytic Hierarchy Process (AHP) Verfahren gegenüber der Nutzwertanalyse bevorzugt. Bei AHP wird durch den hierarchischen Analyseprozess die Evaluation stark strukturiert. Der Analyseprozess unterstützt mit einer Softwareanwendung erlaubt die neutrale Berechnung der zu untersuchenden Lösungsvarianten. Bei vielen zu vergleichenden Kriterien erwächst zwar schnell ein etwas höherer Arbeitsaufwand, das Ergebnis der Analyse ist aber jederzeit gut dokumentiert und nachvollziehbar.
Für die Evaluation wurde jeweils ein Produktevertreter für jede der zu untersuchenden Speicherarchitekturen gewählt. Es wurden die heute am Markt angebotenen Architekturlösungen berücksichtigt, wie die Block-basierenden, Datei-basierenden und Objekt-basierenden Produkte. Ferner wurden ein Vertreter von Online Speicher (Amazon S3) und der bisherige Anbieter der bestehenden Lösung einbezogen. Anbieter von Cloud-Speicherplatz wie Google Drive, iCloud, myDrive oder Dropbox bieten zwar Speicherlösungen für Endanwender (consumer frontend services) an, konnten aber wegen der fehlenden Möglichkeit die bestehende Anwendung des Auftraggebers einzubinden, nicht berücksichtigt werden. 
Untersucht wurde zudem die Eignung von einer Private Cloud. Private Cloud beinhaltet den Aufbau eines eigenen Datencenters basierend auf der OpenStack Object Storage Lösung, währendem bei Public Cloud Hosting-Anbieter gemeint sind, welche die gesamte IT-Infrastruktur mit einer bestimmten Speicherarchitektur samt Unterhalt und Verwaltung als Service anbieten. Es hat sich gezeigt, dass der Betrieb eines eigenen Datencenters mit eigenen Mitarbeitern zwar interessant ist, sich finanziell im Vergleich zu Hosting-Lösungen jedoch nicht rechnet.
Als Vertreter für Block-basierende Speicher wurde das Speichersystem des Herstellers NetApp gewählt, welches den Speicher über iSCSI den Applikations-Servern zur Verfügung stellt. Als Vertreter für Datei-basierende Speicher wurde dieselbe NetApp gewählt, welche den Speicher auch über NFS den Applikations-Servern zur Verfügung stellt. Als Vertreter von Objekt-basierenden Speichern wurde OpenStack Object Storage gewählt, die ebenfalls für Online Speicher eingesetzt wird. OpenStack Object Storage verwendet für die Speicherung gewöhnliche Computer-Systeme und erreicht durch redundante Verteilung der Daten eine hohe Verfügbarkeit. Dabei sind alle Daten auf mindestens drei Computer-Systemen gespeichert. Als Vertreter von Online Speicher wurde Amazon S3 berücksichtigt.Das Evaluationsresultat empfiehlt als Gewinner für beide der oben beschriebenen Speicherbedarfsszenerien Amazon S3. Amazon S3 erhielt wegen den niedrigen Gesamtkosten, der beliebig skalierbaren Speicherkapazität, der hohen Redundanz und für die Sicherstellung der Datenintegrität die meisten Punkte. An zweiter Stelle bei Szenario zwei platzierte sich NetApp iSCSI dicht gefolgt von OpenStack Object Storage, welche beide aufgrund der hohen Personalkosten sich hinter Amazon S3 klassierten.
Für die OpenStack Object Storage wurde ein geeignetes System für die Machbarkeitsstudie aufgebaut und erfolgreich getestet. Aufgrund dass sich Amazon S3 und OpenStack Object Storage ändeln, kann abgeleitet werden, dass auch die empfohlene Lösung mit Amazon S3 umsetzbar ist. 